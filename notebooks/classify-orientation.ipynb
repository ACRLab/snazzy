{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Embryo Orientation \n",
    "\n",
    "Uses a Support Vector Classifier to estimate if the embryo is in ventral or lateral orientation.\n",
    "\n",
    "The classification is important because the VNC length calculation depends on the embryo orientation. \n",
    "This is therefore the first step for calculating VNC length.\n",
    "\n",
    "We need annotated data to train the SVC. \n",
    "The classification is going to be done inspecting the first movie frames, so it's important to annotate frames that also belong to the beggining of the movie.\n",
    "To speed up processing, the images were downsampled and saved as numpy arrays.\n",
    "I used the first 300 frames of each movie to collect the annotated data. \n",
    "Annotated data is not very time consuming: you can visualize one embryo with `pre_process.display` and save its features with `feature_extraction.extract`.\n",
    "This means that from a single movie you can already take 300 data points, since the embryo usually holds the same orientation, specially at the beginning of the episodes.\n",
    "\n",
    "The features will be saved at `./data/downsampled/features/`.\n",
    "We can then feed the data to the SVC, and check the cross validation score.\n",
    "\n",
    "Once the model is built, we can predict new data.\n",
    "In practice, we will first check if there are available trained models, if not we'll fit a new SVC and save the results for future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pasnascope import pre_process, feature_extraction, classifier\n",
    "\n",
    "project_dir = Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies are first downsampled to speed up feature calculation.\n",
    "\n",
    "To downsample, call `pre_process.downsample_all`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join(project_dir, 'data', 'embs')\n",
    "downsampled_dir = os.path.join(project_dir, 'data', 'downsampled')\n",
    "\n",
    "# pre_process.downsample_all(img_dir, downsampled_dir)\n",
    "\n",
    "file_names = sorted([f for f in os.listdir(downsampled_dir) if f.startswith('ds')])\n",
    "\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example on how to inspect a movie to annotate it.\n",
    "\n",
    "To display the movie, change `show` to `True` and select the file index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = True\n",
    "i = 13\n",
    "if show:\n",
    "    pre_process.display(os.path.join(downsampled_dir, file_names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features\n",
    "\n",
    "Features calculated are: centroid x and y positions, first and second Hu moments, and area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = os.path.join(project_dir, 'data', 'downsampled', 'features')\n",
    "\n",
    "feature_extraction.extract_all(downsampled_dir, save=True, output=feature_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the SVC\n",
    "\n",
    "We are ready to pass the features to the SVC.\n",
    "The data still needs to be annotated (each feature file must be associated with a ventral or lateral orientation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(project_dir, 'data', 'models')\n",
    "samples_dir = os.path.join(project_dir, 'data', 'downsampled', 'features')\n",
    "\n",
    "# Flip save to True to actually save the model\n",
    "classifier.fit_SVC(1000, samples_dir, save=False, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "img_path = os.path.join(project_dir, 'data', 'embs')\n",
    "model_path = os.path.join(project_dir, 'data', 'models', 'SVC')\n",
    "imgs = [f for f in os.listdir(img_path) if f.endswith('ch2.tif')]\n",
    "\n",
    "# Display an m x n grid of images with the corresponding prediction\n",
    "m = 4\n",
    "n = 4\n",
    "fig, ax = plt.subplots(m, n)\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        orientation = classifier.classify_image(\n",
    "            os.path.join(img_path, imgs[4*i+j]), model_path)\n",
    "\n",
    "        img_to_classify = classifier.pre_process_tiff(\n",
    "            os.path.join(img_path, imgs[4*i+j]))\n",
    "        ax[i][j].set_title(f\"{imgs[4*i+j][:-8]} - {orientation.upper()}\")\n",
    "        ax[i][j].imshow(img_to_classify)\n",
    "        ax[i][j].set_axis_off()\n",
    "\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.resizable = False\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pasnascope_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
